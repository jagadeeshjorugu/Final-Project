Source Code:
Training.py From ultralytics import YOLO
# Load YOLOv8 model model = YOLO("yolov8m.pt") # You can also use yolov8s.pt, yolov8m.pt, etc.
# Train YOLO on custom dataset model.train(data="datasetfinal/data.yaml", epochs=20, imgsz=416, batch=16) Arduino code #include <TM1637Display.h>
// Pins for TM1637 display #define CLK D3 #define DIO D4
// Motor driver pins const int dirPin = D0; const int stepPin = D1;
// LED Pins for each direction (Green LEDs only) #define LED_N D5 // Lane 0 #define LED_E D6 // Lane 1 #define LED_S D7 // Lane 2 #define LED_W D8 // Lane 3 (after rotation back)
const int stepsPerRevolution = 50; // For 90-degree step const int stepDelay = 4000;
// Microseconds
TM1637Display display(CLK, DIO); int rotationCount = 0; // 0 → N, 1 → E, 2 → S, 3 → W (back)
void setup() { pinMode(stepPin, OUTPUT); pinMode(dirPin, OUTPUT); Serial.begin(9600);
display.setBrightness(5); display.showNumberDec(0);
// LED setup pinMode(LED_N, OUTPUT); pinMode(LED_E, OUTPUT); pinMode(LED_S, OUTPUT);
19pinMode(LED_W, OUTPUT);
allLEDsOff();
}
void countdown(int value) {
for (int i = value; i >= 1; i--) {
display.showNumberDec(i, false);
delay(1000);
}
display.showNumberDec(0, false);
}
void motorRotateClockwise() {
digitalWrite(dirPin, HIGH);
for (int i = 0; i < stepsPerRevolution; i++) {
digitalWrite(stepPin, HIGH);
delayMicroseconds(stepDelay);
digitalWrite(stepPin, LOW);
delayMicroseconds(stepDelay);
}
}
void motorRotateAntiClockwise(int steps) {
digitalWrite(dirPin, LOW);
for (int i = 0; i < steps; i++) {
digitalWrite(stepPin, HIGH);
delayMicroseconds(stepDelay);
digitalWrite(stepPin, LOW);
delayMicroseconds(stepDelay);
}
}
void setGreenLED(int direction) {
// Turn on only the green LED for the current direction
digitalWrite(LED_N, direction == 0 ? HIGH : LOW);
digitalWrite(LED_E, direction == 1 ? HIGH : LOW);
digitalWrite(LED_S, direction == 2 ? HIGH : LOW);
digitalWrite(LED_W, direction == 3 ? HIGH : LOW);
}
void allLEDsOff() {
digitalWrite(LED_N, LOW);
digitalWrite(LED_E, LOW);
digitalWrite(LED_S, LOW);
digitalWrite(LED_W, LOW);
}
void loop() {
int latestCount = -1;
20// Receive vehicle count from Python (via serial)
while (Serial.available()) {
int incoming = Serial.parseInt();
if (incoming > 0 && incoming < 100) {
latestCount = incoming;
}
delay(10);
}
if (latestCount != -1) {
int countdown_time = latestCount * 10;
Serial.print("Received count: ");
Serial.println(latestCount);
// Set the green LED based on current rotation
setGreenLED(rotationCount);
countdown(countdown_time);
// If last direction (West, i.e., rotationCount = 3)
if (rotationCount == 3) {
Serial.println("Rotating back 270°...");
motorRotateAntiClockwise(stepsPerRevolution * 3);
allLEDsOff(); // turn off LEDs
rotationCount = 0;
Serial.println("Waiting for next value...");
delay(5000); // pause before next cycle
while (Serial.available() == 0); // Wait for next count
} else {
motorRotateClockwise();
rotationCount++;
}
Serial.println("DONE");
}
}
App.py
from flask import Flask, render_template
import threading
app = Flask(_name_)
# Global variable for total vehicle count (you can update this from another thread)
traffic_data = {"total": 0}
@app.route('/')
def index():
total = traffic_data["total"]
21# Traffic status logic
if total == 0:
status = "No Traffic Detected"
elif total > 12:
status = "Heavy Traffic Detected"
elif total > 6:
status = "Medium Traffic Detected"
else:
status = "Low Traffic Detected"
return render_template("index.html", total=total, status=status)
def run_app():
app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False)
No of vehicles.py
import cv2
import serial
import time
from ultralytics import YOLO
from app import traffic_data, run_app
import threading
# Start Flask in a separate thread
threading.Thread(target=run_app).start()
# Load YOLOv8 model
model = YOLO("best.pt")
arduino = serial.Serial('COM8', 9600)
time.sleep(2)
cap = cv2.VideoCapture(0)
cap.set(3, 640)
cap.set(4, 480)
lane_counter = 0
total_vehicles = 0
while True:
ret, frame = cap.read()
if not ret:
print("Camera not accessible")
break
results = model(frame, conf=0.8)
vehicle_count = 0
for result in results:
for box in result.boxes:
cls_id = int(box.cls[0])
22label = model.names[cls_id]
if label in ["car", "bus", "truck", "motorcycle"]:
vehicle_count += 1
x1, y1, x2, y2 = map(int, box.xyxy[0])
cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
cv2.putText(frame, label, (x1, y1 - 10),
cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
cv2.putText(frame, f"Vehicles: {vehicle_count}", (10, 30),
cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
total_vehicles += vehicle_count
lane_counter += 1
print(f"[Lane {lane_counter}] Sending: {vehicle_count}")
arduino.write(f"{vehicle_count}\n".encode())
frozen_frame = frame.copy()
wait_time = vehicle_count * 10
print(f"Waiting {wait_time} sec showing frozen frame...")
start = time.time()
while time.time() - start < wait_time:
cv2.imshow("Vehicle Detection", frozen_frame)
if cv2.waitKey(1) & 0xFF == ord('q'):
break
if lane_counter == 4:
print(f"\nTotal vehicles in 4 lanes: {total_vehicles}")
traffic_data["total"] = total_vehicles #      Share with Flask
lane_counter = 0
total_vehicles = 0
print("Waiting for next rotation cycle...\n")
time.sleep(3)
if cv2.waitKey(1) & 0xFF == ord('q'):
break
cap.release()
cv2.destroyAllWindows()
arduino.close()
Testing.py
from ultralytics import YOLO
import cv2
# Load the trained YOLOv8 model
model = YOLO("best.pt") # Replace with your trained model
# Open the webcam
23cap = cv2.VideoCapture(0) # Use 0 for the default webcam
# Set frame width & height (optional)
cap.set(3, 640) # Width
cap.set(4, 480) # Height
while cap.isOpened():
success, frame = cap.read()
if not success:
print("Failed to grab frame")
break
# Perform object detection
results = model(frame, conf=0.6) # Adjust confidence threshold if needed
# Draw bounding boxes
for result in results:
for box in result.boxes:
x1, y1, x2, y2 = map(int, box.xyxy[0]) # Bounding box
conf = box.conf[0].item() # Confidence score
cls = int(box.cls[0].item()) # Class index
label = f"{model.names[cls]} {conf:.2f}" # Label with confidence
# Draw rectangle and label
cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2) # Blue bounding box
cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
# Display the frame
cv2.imshow("YOLOv8 Live Detection", frame)
# Press 'q' to exit
if cv2.waitKey(1) & 0xFF == ord('q'):
break
# Release resources
cap.release()
cv2.destroyAllWindows()
Livecam.py
import cv2
import time
# Open webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
print("  Cannot open camera")
exit()
while True:
ret, frame = cap.read()
24if not ret:
print("  Can't receive frame (stream end?). Exiting ...")
break
cv2.imshow('Live Camera - Press S to Save, ESC to Exit', frame)
key = cv2.waitKey(1) & 0xFF
if key == 27: # ESC key to exit
break
elif key == ord('s'):
# Save image with timestamp
filename = f"snapshot_{int(time.time())}.jpg"
cv2.imwrite(filename, frame)
print(f"   Image saved as {filename}")
cap.release()
cv2.destroyAllWindows()
Index.html
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Traffic Density Monitoring</title>
<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap"
rel="stylesheet">
<style>
body {
font-family: 'Poppins', sans-serif;
background: linear-gradient(135deg, #2980b9, #6dd5fa, #ffffff);
background-size: 400% 400%;
animation: gradientBG 15s ease infinite;
margin: 0;
padding: 0;
text-align: center;
color: #333;
}
@keyframes gradientBG {
0% {background-position: 0% 50%;}
50% {background-position: 100% 50%;}
100% {background-position: 0% 50%;}
}
header {
padding: 30px;
background-color: rgba(0, 0, 0, 0.6);
color: white;
}
25h1 {
font-size: 3em;
margin: 0;
}
.container {
margin-top: 60px;
display: flex;
flex-direction: column;
align-items: center;
}
.card {
background: white;
padding: 30px 50px;
border-radius: 15px;
box-shadow: 0 8px 25px rgba(0,0,0,0.15);
max-width: 400px;
margin: 20px auto;
}
.card h2 {
font-size: 2em;
color: #2980b9;
}
.status {
font-size: 1.5em;
font-weight: 600;
color: #fff;
background-color: #27ae60;
padding: 10px 20px;
border-radius: 10px;
margin-top: 15px;
}
.status.medium {
background-color: #f39c12;
}
.status.heavy {
background-color: #e74c3c;
}
footer {
position: fixed;
bottom: 10px;
width: 100%;
color: #ffffffcc;
font-size: 0.9em;
26}
</style>
</head>
<body>
<header>
<h1>     Traffic Density Monitoring System</h1>
</header>
<div class="container">
<div class="card">
<h2>Total Vehicles: {{ total }}</h2>
<div class="status
{% if 'Heavy' in status %}heavy{% elif 'Medium' in status %}medium{% else %}low{% endif
%}">
{{ status }}
</div>
</div>
</div>
<footer>
&copy; 2025 Traffic Smart Systems. All rights reserved.
</footer>
</body>
</html>
Data.yaml
train: C:\Users\DELL\OneDrive\Desktop\finalproject\datasetfinal\images
val: C:\Users\DELL\OneDrive\Desktop\finalproject\datasetfinal\images
nc: 1 # Change based on number of classes
names: ["car"] # Replace with actual class names

